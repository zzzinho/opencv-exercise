{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "input_shape = x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/20\n60000/60000 [==============================] - 20s 331us/sample - loss: 0.1706 - sparse_categorical_accuracy: 0.9492 - val_loss: 0.0514 - val_sparse_categorical_accuracy: 0.9841\nEpoch 2/20\n60000/60000 [==============================] - 19s 319us/sample - loss: 0.0484 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.0368 - val_sparse_categorical_accuracy: 0.9878\nEpoch 3/20\n60000/60000 [==============================] - 20s 326us/sample - loss: 0.0324 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.0267 - val_sparse_categorical_accuracy: 0.9909\nEpoch 4/20\n60000/60000 [==============================] - 20s 335us/sample - loss: 0.0248 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0287 - val_sparse_categorical_accuracy: 0.9907\nEpoch 5/20\n60000/60000 [==============================] - 19s 318us/sample - loss: 0.0184 - sparse_categorical_accuracy: 0.9945 - val_loss: 0.0326 - val_sparse_categorical_accuracy: 0.9894\nEpoch 6/20\n60000/60000 [==============================] - 19s 320us/sample - loss: 0.0144 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.0325 - val_sparse_categorical_accuracy: 0.9894\nEpoch 7/20\n60000/60000 [==============================] - 20s 326us/sample - loss: 0.0124 - sparse_categorical_accuracy: 0.9956 - val_loss: 0.0332 - val_sparse_categorical_accuracy: 0.9895\nEpoch 8/20\n60000/60000 [==============================] - 19s 320us/sample - loss: 0.0093 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0295 - val_sparse_categorical_accuracy: 0.9913\nEpoch 9/20\n60000/60000 [==============================] - 19s 315us/sample - loss: 0.0085 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0339 - val_sparse_categorical_accuracy: 0.9904\nEpoch 10/20\n60000/60000 [==============================] - 19s 324us/sample - loss: 0.0075 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0313 - val_sparse_categorical_accuracy: 0.9908\nEpoch 11/20\n60000/60000 [==============================] - 20s 328us/sample - loss: 0.0059 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0296 - val_sparse_categorical_accuracy: 0.9915\nEpoch 12/20\n60000/60000 [==============================] - 20s 328us/sample - loss: 0.0054 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0314 - val_sparse_categorical_accuracy: 0.9907\nEpoch 13/20\n60000/60000 [==============================] - 20s 333us/sample - loss: 0.0038 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0358 - val_sparse_categorical_accuracy: 0.9913\nEpoch 14/20\n60000/60000 [==============================] - 20s 341us/sample - loss: 0.0043 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0267 - val_sparse_categorical_accuracy: 0.9932\nEpoch 15/20\n60000/60000 [==============================] - 20s 340us/sample - loss: 0.0042 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0365 - val_sparse_categorical_accuracy: 0.9909\nEpoch 16/20\n60000/60000 [==============================] - 21s 346us/sample - loss: 0.0048 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0384 - val_sparse_categorical_accuracy: 0.9893\nEpoch 17/20\n60000/60000 [==============================] - 20s 331us/sample - loss: 0.0022 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.0346 - val_sparse_categorical_accuracy: 0.9918\nEpoch 18/20\n60000/60000 [==============================] - 20s 337us/sample - loss: 0.0033 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.0324 - val_sparse_categorical_accuracy: 0.9933\nEpoch 19/20\n60000/60000 [==============================] - 19s 311us/sample - loss: 0.0038 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0347 - val_sparse_categorical_accuracy: 0.9921\nEpoch 20/20\n60000/60000 [==============================] - 19s 321us/sample - loss: 0.0032 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0426 - val_sparse_categorical_accuracy: 0.9915\n"
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=100, epochs=20, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/jeongjinho/vscode/tensorflow/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: mnist_cnn.pb/assets\n"
    }
   ],
   "source": [
    "model.save('mnist_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitvenvvenvafb118ae0f7c4903a06eca2382c981a7",
   "display_name": "Python 3.7.7 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}